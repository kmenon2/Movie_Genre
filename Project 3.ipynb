{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CSE 587: Project 3\n",
    "#### Members: Thankam Abish, Krishna Menon, Lucas Bietzel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Pyspark demo\") \\\n",
    "    .config(\"spark.some.config.option\",\"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ADJUST TO CORRECT FILE PATHS\n",
    "\n",
    "dfs = spark.read.csv('/home/cse587/A3Data/train.csv', escape='\"', inferSchema = 'True',header=\"True\")\n",
    "testdfs = spark.read.csv('/home/cse587/A3Data/test.csv', escape='\"', inferSchema = 'True',header=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "### SMALL DATAFRAME USED FOR TESTING\n",
    "#dfs = spark.createDataFrame([\n",
    " #   (12340, \"Hi hi HI HI  , HI HI\", \"['Drama','Comedy']\"),\n",
    "  #  (123545, \"I wish Java could use case classes\", \"['Drama','Comedy','Action']\"),\n",
    "   # (2123, \"things are really neat. wow\", \"['Action','Comedy','Horror']\"),\n",
    "    #(21523, \"fat cats are cute\", \"['Action','Comedy','Horror']\")], \n",
    "    #[\"id\", \"plot\", \"genre\"])\n",
    "    \n",
    "#testdfs = spark.createDataFrame([\n",
    " #   (12640, \"Hi wish cats\")],\n",
    "  #  [\"id\", \"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FIND BAD DATA\n",
    "\n",
    "def to_fix(x):\n",
    "    try:\n",
    "        eval(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "fix_udf = udf(lambda x: to_fix(x), BooleanType())\n",
    "dfs2 = dfs.withColumn('validity', fix_udf('genre'))\n",
    "dfs2.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs2.filter(col(\"validity\")==True)\n",
    "dfs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.dropna()\n",
    "dfs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot text cleaning, shows the clean text \n",
    "def clean(x):\n",
    "    dfs2 = x.withColumn('plot', (col('plot')).cast(StringType()))\n",
    "    text = regexp_replace(dfs2['plot'], \"[^a-zA-Z ]\",\"\")\n",
    "    text = regexp_replace(text, ' +', ' ')\n",
    "    dfs2 = dfs2.withColumn('plot', text)\n",
    "    dfs2.show()\n",
    "    dfs2 = dfs2.withColumn('plot', lower(col('plot')))\n",
    "    dfs2.show()\n",
    "    c = split(dfs2['plot'],' ')\n",
    "    dfs2 = dfs2.withColumn('plot', c)\n",
    "    dfs2.show()\n",
    "\n",
    "    ##stop word removal\n",
    "    remover = StopWordsRemover(inputCol=\"plot\", outputCol=\"filtered\")\n",
    "    dfs2 = remover.transform(dfs2)\n",
    "    dfs2 = dfs2.withColumn('plot', col('filtered'))\n",
    "    dfs2 = dfs2.drop('filtered')\n",
    "    return dfs2\n",
    "\n",
    "dfs2 = clean(dfs2)\n",
    "testdfs = clean(testdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs2.printSchema()\n",
    "dfs2.show()\n",
    "testdfs.printSchema()\n",
    "dfs2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "############     PART 1   (ONLY RUN ONE PART)\n",
    "####################################################################\n",
    "cv = CountVectorizer(inputCol=\"plot\", outputCol=\"features\")\n",
    "model = cv.fit(dfs2)\n",
    "dfs3 = model.transform(dfs2)\n",
    "testdfs3 = model.transform(testdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "############     PART 2    (ONLY RUN ONE PART)\n",
    "####################################################################\n",
    "cv = CountVectorizer(inputCol=\"plot\", outputCol=\"rawFeatures\")\n",
    "model = cv.fit(dfs2)\n",
    "dfs3 = model.transform(dfs2)\n",
    "testdfs3 = model.transform(testdfs)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(dfs3)\n",
    "dfs3 = idfModel.transform(dfs3)\n",
    "testdfs3 = idfModel.transform(testdfs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "############     PART 3    (ONLY RUN ONE PART)\n",
    "####################################################################\n",
    "word2Vec = Word2Vec(vectorSize = 100, inputCol=\"plot\", outputCol=\"features\")\n",
    "w2vmodel = word2Vec.fit(dfs2)\n",
    "dfs3 = w2vmodel.transform(dfs2)\n",
    "testdfs3 = w2vmodel.transform(testdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs3.printSchema()\n",
    "dfs3.count()\n",
    "testdfs3.printSchema()\n",
    "dfs3.show()\n",
    "testdfs3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DETECT BAD DATA\n",
    "\n",
    "def to_fix(x): \n",
    "    try:\n",
    "        eval(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "fix_udf = udf(lambda x: to_fix(x), BooleanType())\n",
    "dfs4 = dfs3.withColumn('validity', fix_udf('genre'))\n",
    "dfs4.show()\n",
    "\n",
    "dfs3 = dfs4.filter(col(\"validity\")==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE BINARY LABEL COLUMNS FOR GENRE\n",
    "\n",
    "genres = ['Drama','Comedy','Romance Film','Thriller','Action',\n",
    "          'World cinema','Crime Fiction','Horror','Black-and-white',\n",
    "          'Indie','Action/Adventure','Adventure','Family Film',\n",
    "          'Short Film','Romantic drama','Animation','Musical',\n",
    "          'Science Fiction','Mystery','Romantic comedy']\n",
    "\n",
    "def to_genre(x):\n",
    "    a = eval(x)\n",
    "    b = []\n",
    "    for i in genres:\n",
    "        if i in a:\n",
    "            b.append(1)\n",
    "        else:\n",
    "            b.append(0)\n",
    "    return b\n",
    "\n",
    "to_list_udf = udf(lambda x: to_genre(x), ArrayType(IntegerType()))\n",
    "dfs6 = dfs3.withColumn('genre', to_list_udf('genre'))\n",
    "dfs6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SEPARATED GENRE COLUMNS\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    dfs6=dfs6.withColumn(genres[i],col('genre').getItem(i))\n",
    "dfs6 = dfs6.drop('genre')\n",
    "dfs6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs6.printSchema()\n",
    "dfs6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE MODEL CREATION\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'Drama', maxIter=100)\n",
    "lrModel = lr.fit(dfs6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE TESTING FOR SINGLE MODEL CREATION\n",
    "prediction = lrModel.transform(testdfs3)\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL 20 BINARY CLASSIFIERS\n",
    "import numpy as np\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "biglr = np.array([])\n",
    "biglrModel = np.array([])\n",
    "for i in range(len(genres)):\n",
    "    biglr = np.append(biglr,LogisticRegression(featuresCol = 'features', labelCol = genres[i], maxIter=100))\n",
    "    biglrModel = np.append(biglrModel, biglr[i].fit(dfs6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTIONS FROM BINARY CLASSIFIERS\n",
    "preds = np.array([])\n",
    "for i in range(len(genres)):\n",
    "    a = biglrModel[i].transform(testdfs3)\n",
    "    a = a.withColumn('prediction', col('prediction').cast(IntegerType()))\n",
    "    preds = np.append(preds, a)\n",
    "    preds[i].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MERGE PREDICTIONS\n",
    "final = preds[0].withColumn('id',col('movie_id').cast(StringType())).select(col('id'))\n",
    "final.show()\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    \n",
    "    final = final.join(preds[i], final.id == preds[i].movie_id)\n",
    "    final = final.withColumn(genres[i],col('prediction'))\n",
    "    final = final.drop('movie_name','movie_id','plot','features','rawPrediction','probability','prediction','rawFeatures')\n",
    "    final.show()\n",
    "\n",
    "df = final.withColumn('prediction', \n",
    "                    concat(col('Drama')\n",
    "                          ,lit(' '),col('Comedy')\n",
    "                          ,lit(' '),col('Romance Film')\n",
    "                          ,lit(' '),col('Thriller')\n",
    "                          ,lit(' '),col('Action')\n",
    "                          ,lit(' '),col('World cinema')\n",
    "                          ,lit(' '),col('Crime Fiction')\n",
    "                          ,lit(' '),col('Horror')\n",
    "                          ,lit(' '),col('Black-and-white')\n",
    "                          ,lit(' '),col('Indie')\n",
    "                          ,lit(' '),col('Action/Adventure')\n",
    "                          ,lit(' '),col('Adventure')\n",
    "                          ,lit(' '),col('Family Film')\n",
    "                          ,lit(' '),col('Short Film')\n",
    "                          ,lit(' '),col('Romantic drama')\n",
    "                          ,lit(' '),col('Animation')\n",
    "                          ,lit(' '),col('Musical')\n",
    "                          ,lit(' '),col('Science Fiction')\n",
    "                          ,lit(' '),col('Mystery')\n",
    "                          ,lit(' '),col('Romantic comedy')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPARING FORMAT FOR CSV FILE\n",
    "\n",
    "convertToCSV = df.select(col('id').alias('movie_id'),col('prediction'))\n",
    "convertToCSV.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE TO CSV\n",
    "convertToCSV = convertToCSV.withColumn('movie_id', col('movie_id').cast(IntegerType()))\n",
    "convertToCSV.printSchema()\n",
    "convertToCSV.write.csv('Part2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
